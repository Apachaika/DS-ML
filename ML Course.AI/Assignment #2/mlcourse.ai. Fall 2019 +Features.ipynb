{"cells":[{"metadata":{},"cell_type":"markdown","source":"<center>\n<img src=\"https://habrastorage.org/files/fd4/502/43d/fd450243dd604b81b9713213a247aa20.jpg\" />\n</center> \n     \n## <center>  [mlcourse.ai](https://mlcourse.ai) – Open Machine Learning Course \n\n#### <center> Author: [Yury Kashnitsky](https://yorko.github.io) (@yorko) \n\n# <center>Assignment #2. Fall 2019\n## <center> Part 2. Gradient boosting"},{"metadata":{},"cell_type":"markdown","source":"**In this assignment, you're asked to beat a baseline in the [\"Flight delays\" competition](https://www.kaggle.com/c/flight-delays-fall-2018).**\n\nThis time we decided to share a pretty decent CatBoost baseline, you'll have to improve the provided solution.\n\nPrior to working on the assignment, you'd better check out the corresponding course material:\n 1. [Classification, Decision Trees and k Nearest Neighbors](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic03_decision_trees_kNN/topic3_decision_trees_kNN.ipynb?flush_cache=true), the same as an interactive web-based [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-3-decision-trees-and-knn) \n 2. Ensembles:\n  - [Bagging](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part1_bagging.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-1-bagging)\n  - [Random Forest](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part2_random_forest.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-2-random-forest)\n  - [Feature Importance](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part3_feature_importance.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-3-feature-importance)\n 3. - [Gradient boosting](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic10_boosting/topic10_gradient_boosting.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-10-gradient-boosting) \n   - Logistic regression, Random Forest, and LightGBM in the \"Kaggle Forest Cover Type Prediction\" competition: [Kernel](https://www.kaggle.com/kashnitsky/topic-10-practice-with-logit-rf-and-lightgbm) \n 4. You can also practice with demo assignments, which are simpler and already shared with solutions:\n  - \"Decision trees with a toy task and the UCI Adult dataset\": [assignment](https://www.kaggle.com/kashnitsky/a3-demo-decision-trees) + [solution](https://www.kaggle.com/kashnitsky/a3-demo-decision-trees-solution)\n  - \"Logistic Regression and Random Forest in the credit scoring problem\": [assignment](https://www.kaggle.com/kashnitsky/assignment-5-logit-and-rf-for-credit-scoring) + [solution](https://www.kaggle.com/kashnitsky/a5-demo-logit-and-rf-for-credit-scoring-sol)\n 5. There are also 7 video lectures on trees, forests, boosting and their applications: [mlcourse.ai/video](https://mlcourse.ai/video) \n 6. mlcourse.ai tutorials on [categorical feature encoding](https://www.kaggle.com/waydeherman/tutorial-categorical-encoding) (by Wayde Herman) and [CatBoost](https://www.kaggle.com/mitribunskiy/tutorial-catboost-overview) (by Mikhail Tribunskiy)\n 7. Last but not the least: [Public Kernels](https://www.kaggle.com/c/flight-delays-fall-2018/notebooks) in this competition\n\n### Your task is to:\n 1. beat **\"A2 baseline (10 credits)\"** on Public LB (**0.75914** LB score)\n 2. rename your [team](https://www.kaggle.com/c/flight-delays-fall-2018/team) in full accordance with A1 and the [course rating](https://docs.google.com/spreadsheets/d/15e1K0tg5ponA5R6YQkZfihrShTDLAKf5qeKaoVCiuhQ/) (to appear on 16.09.2019)\n \nThis task is intended to be relatively easy. Here you are not required to upload your reproducible solution.\n \n### <center> Deadline for A2: 2019 October 6, 20:59 CET (London time)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom catboost import Pool, CatBoostClassifier, cv\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n\nfrom scipy.stats import uniform as sp_randFloat\nfrom scipy.stats import randint as sp_randInt ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Read the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH_TO_DATA = Path('../input/flight-delays-fall-2018/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(PATH_TO_DATA / 'flight_delays_train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(PATH_TO_DATA / 'flight_delays_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create only one feature - “flight” (this you need to improve - add more features)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['flight'] = train_df['Origin'] + '=>' + train_df['Dest']\ntest_df['flight'] = test_df['Origin'] + '=>' + test_df['Dest']\n\ntrain_df['flight_back'] = train_df['Dest'] + '<=' + train_df['Origin']\ntest_df['flight_back'] = test_df['Dest'] + '<=' + test_df['Origin']\ntrain_df['flight_carrier'] = train_df['UniqueCarrier'] + '=' + train_df['flight']\ntest_df['flight_carrier'] = test_df['UniqueCarrier'] + '=' + test_df['flight']\n\n\"\"\"for col in ['UniqueCarrier', 'Origin', 'Dest', 'flight', 'flight_back', 'flight_carrier']:\n    train_df[col] = pd.factorize(train_df[col])[0]\nfor col in ['UniqueCarrier', 'Dest', 'Origin', 'flight', 'flight_back', 'flight_carrier']:\n    test_df[col] = pd.factorize(test_df[col])[0]\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add DepHour\ntrain_df['DepHour'] = train_df['DepTime'] // 100\n#add DepMin\ntrain_df['Dep_minute'] =  train_df['DepTime']%100\ntrain_df['DepHour'].replace(to_replace=[24,25], value=0, inplace=True)\n\n#Add DepHour + minute\ntest_df['DepHour'] = test_df['DepTime'] // 100\ntest_df['Dep_minute'] =  test_df['DepTime']%100\ntest_df['DepHour'].replace(to_replace=[24,25], value=0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Daytime\n\"\"\"train_df['daytime'] = pd.cut(train_df['DepHour'], bins=[0, 6, 12, 18, 23], include_lowest=True).astype('object')\ntest_df['daytime'] = pd.cut(test_df['DepHour'], bins=[0, 6, 12, 18, 23], include_lowest=True).astype('object')\n\nfor col in ['daytime']:\n    train_df[col] = pd.factorize(train_df[col])[0]\nfor col in ['daytime']:\n    test_df[col] = pd.factorize(test_df[col])[0]\"\"\"\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['s_hour'] = np.sin(2*np.pi*test_df['DepHour']/24)\ntest_df['c_hour'] = np.cos(2*np.pi*test_df['DepHour']/24)\n\ntrain_df['s_hour'] = np.sin(2*np.pi*train_df['DepHour']/24)\ntrain_df['c_hour'] = np.cos(2*np.pi*train_df['DepHour']/24)\n\ntrain_df['Dep_hour_flag'] = ((train_df['DepHour'] >= 6) & (train_df['DepHour'] < 23)).astype(np.int64)\ntest_df['Dep_hour_flag'] = ((test_df['DepHour'] >= 6) & (test_df['DepHour'] < 23)).astype(np.int64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['summer'] = (train_df['Month'].isin(['c-6', 'c-7', 'c-8'])).astype(np.int64)\ntrain_df['autumn'] = (train_df['Month'].isin(['c-9', 'c-10', 'c-11'])).astype(np.int64)\ntrain_df['winter'] = (train_df['Month'].isin(['c-12', 'c-1', 'c-2'])).astype(np.int64)\ntrain_df['spring'] = (train_df['Month'].isin(['c-3', 'c-4', 'c-5'])).astype(np.int64)\n\ntest_df['summer'] = (test_df['Month'].isin(['c-6', 'c-7', 'c-8'])).astype(np.int64)\ntest_df['autumn'] = (test_df['Month'].isin(['c-9', 'c-10', 'c-11'])).astype(np.int64)\ntest_df['winter'] = (test_df['Month'].isin(['c-12', 'c-1', 'c-2'])).astype(np.int64)\ntest_df['spring'] = (test_df['Month'].isin(['c-3', 'c-4', 'c-5'])).astype(np.int64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_df['delay_time'] = ((train_df['DepHour'] >= 13) & (train_df['DepHour'] < 24) | (train_df['DepHour'] < 5)).astype('int64')\n#train_df['other_time'] = ((train_df['DepHour'] < 9) & (train_df['DepHour'] >=5)).astype('object')\n#train_df['middle_time'] = ((train_df['DepHour'] >= 9) & (train_df['DepHour'] < 13)).astype('object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_df['delay_time'] = ((test_df['DepHour'] >= 13) & (test_df['DepHour'] < 24) | (test_df['DepHour'] < 5)).astype('int64')\n#test_df['other_time'] = ((test_df['DepHour'] < 9) & (test_df['DepHour'] >=5)).astype('object')\n#test_df['middle_time'] = ((test_df['DepHour'] >= 9) & (test_df['DepHour'] < 13)).astype('object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"train_df['morning'] = ((train_df['DepHour'] >= 6) & (train_df['DepHour'] < 12)).astype(np.int32)\ntrain_df['day'] = ((train_df['DepHour'] >= 12) & (train_df['DepHour'] < 18)).astype(np.int32)\ntrain_df['evening'] = ((train_df['DepHour'] >= 18) & (train_df['DepHour'] < 24)).astype(np.int32)\ntrain_df['night'] = ((train_df['DepHour'] >= 0) & (train_df['DepHour'] < 6)).astype(np.int32)\ntrain_df['low_delay'] = ((train_df['DepHour'] >= 4) & (train_df['DepHour'] < 9)).astype(np.int32)\n#train_df['high_delay'] = ((train_df['DepHour'] >= 4) & (train_df['DepHour'] < 9)).astype(np.int32)\n\ntest_df['morning'] = ((test_df['DepHour'] >= 6) & (test_df['DepHour'] < 12)).astype(np.int32)\ntest_df['day'] = ((test_df['DepHour'] >= 12) & (test_df['DepHour'] < 18)).astype(np.int32)\ntest_df['evening'] = ((test_df['DepHour'] >= 18) & (test_df['DepHour'] < 24)).astype(np.int32)\ntest_df['night'] = ((test_df['DepHour'] >= 0) & (test_df['DepHour'] < 6)).astype(np.int32)\ntest_df['low_delay'] = ((test_df['DepHour'] >= 4) & (test_df['DepHour'] < 9)).astype(np.int32)\n#test_df['high_delay'] = ((test_df['DepHour'] >= 4) & (test_df['DepHour'] < 9)).astype(np.int32)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"train_df['month_x'] = ((train_df['Month'].str[2:].isin([12, 6, 7]))).astype('int')\ntest_df['month_x'] = ((test_df['Month'].str[2:].isin([12, 1]))).astype('int')\n\ntrain_df['month_y'] = ((train_df['Month'].str[2:].isin([4, 5, 9, 2]))).astype('int')\ntest_df['month_y'] = ((test_df['Month'].str[2:].isin([12, 1]))).astype('int')\"\"\"\n#train_df['winter'] = ((train_df['Month'].isin([12, 1, 2]))).astype('int')\n#test_df['winter'] = ((test_df['Month'].isin([12, 1, 2]))).astype('int')\n\n#train_df['spring'] = ((train_df['Month'].isin([3, 4, 5]))).astype('int')\n#test_df['spring'] = ((test_df['Month'].isin([3, 4, 5]))).astype('int')\n\n#train_df['summer'] = ((train_df['Month'].isin([6, 7, 8]))).astype('int')\n#test_df['summer'] = ((test_df['Month'].isin([6, 7, 8]))).astype('int')\n\n\"\"\"train_df['autumn'] = ((train_df['Month'].isin([9, 10, 11]))).astype('int')\ntest_df['autumn'] = ((test_df['Month'].isin([9, 10, 11]))).astype('int')\"\"\"\n\"\"\"train_df['week_high'] = ((df_train['DayOfWeek'].isin([4, 5, 1, 7]))).astype('int')\ntest_df['week_high'] = ((test_df['DayOfWeek'].isin([12, 1, 2]))).astype('int')\n\ntrain_df['week_low'] = ((df_train['DayOfWeek'].isin([6, 2, 3]))).astype('int')\ntest_df['week_low'] = ((test_df['DayOfWeek'].isin([12, 1, 2]))).astype('int')\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['DepHour']:\n    train_df[col] = train_df[col].astype('object')\nfor col in ['DepHour']:\n    test_df[col] = test_df[col].astype('object')\n    \nfor col in ['DepTime',]:\n    train_df = train_df.drop([col], axis=1)\nfor col in ['DepTime', ]:\n    test_df= test_df.drop([col], axis=1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"for col in ['Month', 'DayofMonth', 'DayOfWeek']:\n    train_df[col] = train_df[col].apply(lambda x: x.split('-')[1]).astype(np.int32) - 1\nfor col in ['Month', 'DayofMonth', 'DayOfWeek']:\n    test_df[col] = test_df[col].apply(lambda x: x.split('-')[1]).astype(np.int32) - 1\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Remember indexes of categorical features (to be passed to CatBoost)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"categ_feat_idx = np.where(train_df.drop('dep_delayed_15min', axis=1).dtypes == 'object')[0]\ncateg_feat_idx","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Allocate a hold-out set (a.k.a. a validation set) to validate the model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_df.drop('dep_delayed_15min', axis=1).values\ny_train = train_df['dep_delayed_15min'].map({'Y': 1, 'N': 0}).values\nX_test = test_df.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_test.shape, y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = train_df.drop('dep_delayed_15min', axis=1).corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(10,10))\n#plot heat map\ng=sns.heatmap(train_df.drop('dep_delayed_15min', axis=1).corr(),annot=True,cmap=\"RdYlGn\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_part, X_valid, y_train_part, y_valid = train_test_split(X_train, y_train, \n                                                                test_size=.1, \n                                                                random_state=7, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Train Catboost with default arguments, passing only the indexes of categorical features.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ctb = CatBoostClassifier(task_type='GPU',loss_function='Logloss',  eval_metric='AUC',   random_seed=14, silent=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nctb.fit(X_train_part, y_train_part,cat_features=categ_feat_idx, eval_set=(X_valid, y_valid), verbose=200);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ctb_valid_pred = ctb.predict_proba(X_valid)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We got some 0.756 ROC AUC on the hold-out set.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(y_valid, ctb_valid_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fea_imp = pd.DataFrame({'imp': ctb.feature_importances_, 'col': train_df.drop('dep_delayed_15min', axis=1)})\nfea_imp = fea_imp.sort_values(['imp', 'col'], ascending=[True, False]).iloc[-30:]\nplt.figure(figsize=(8, 10))\nsns.barplot(x='imp', y='col', data=fea_imp[1:], orient='h')\nplt.title('CatBoost - Feature Importance')\nplt.ylabel('Features')\nplt.xlabel('Importance');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nctb.fit(X_train, y_train, cat_features=categ_feat_idx);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"сtb_test_pred = ctb.predict_proba(X_test)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    \n    sample_sub_clf = pd.read_csv(PATH_TO_DATA / 'sample_submission.csv', \n                             index_col='id')\n    sample_sub_clf['dep_delayed_15min'] = сtb_test_pred\n    sample_sub_clf.to_csv('clf_pred.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!head clf_pred.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('clf_pred.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now's your turn! Go and improve the model to beat **\"A2 baseline (10 credits)\"** - **0.75914** LB score. It's crucial to come up with some good features. \n\nFor discussions, stick to the **#a2_kaggle_fall2019** thread in the **mlcourse_ai_news** [ODS Slack](http://opendatascience.slack.com) channel. Serhii Romanenko (@serhii_romanenko) will be there to help. \n\nWelcome to Kaggle!\n\n<img src='https://habrastorage.org/webt/fs/42/ms/fs42ms0r7qsoj-da4x7yfntwrbq.jpeg' width=50%>\n*from the [\"Nerd Laughing Loud\"](https://www.kaggle.com/general/76963) thread.*"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}